{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ae4228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape\n",
      "(22823, 24)\n",
      "(22823,)\n",
      "After Reshape\n",
      "(22823, 24, 1)\n",
      "(22823,)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "mat = scipy.io.loadmat('xy_Data_new.mat')\n",
    "xy_data = np.array(mat.get('xy_data_scaled', []))\n",
    "np.random.shuffle(xy_data)\n",
    "xy_data = xy_data.round(4)\n",
    "x_data = xy_data[:,0:24]\n",
    "y_data = xy_data[:, 24]\n",
    "print('Before Reshape')\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "\n",
    "x_data = np.resize(x_data, (22823, 24, 1))\n",
    "y_data = np.resize(y_data, (22823,))\n",
    "print('After Reshape')\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "# x_data = np.array(mat.get(\"x_data\", []), ndmin=2)\n",
    "# y_data = np.array(mat.get(\"y_data\", []), ndmin=1)\n",
    "\n",
    "# data = [x_data, y_data]\n",
    "\n",
    "# print('xdata')\n",
    "# print(x_data[0])\n",
    "# print('\\nydata')\n",
    "# print(y_data[0])\n",
    "# print('\\ndata')\n",
    "# print(data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69751ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36895861",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"x_data.pickle\", \"wb\")\n",
    "pickle.dump(x_data, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_data.pickle\", \"wb\")\n",
    "pickle.dump(y_data, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1104f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pickle.load(open(\"x_data.pickle\", \"rb\"))\n",
    "y_data = pickle.load(open(\"y_data.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbd2909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22823, 24, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 24, 32)            4352      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 32)            0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 24, 32)           128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,833\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n",
      "Starting to fit\n",
      "Epoch 1/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.3876 - mean_squared_error: 0.9378\n",
      "Epoch 1: loss improved from inf to 0.38669, saving model to weights.hdf5\n",
      "183/183 [==============================] - 18s 33ms/step - loss: 0.3867 - mean_squared_error: 0.9351 - val_loss: 0.0359 - val_mean_squared_error: 0.0719 - lr: 1.0000e-04\n",
      "Epoch 2/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.2242 - mean_squared_error: 0.4989\n",
      "Epoch 2: loss improved from 0.38669 to 0.22386, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2239 - mean_squared_error: 0.4981 - val_loss: 0.0183 - val_mean_squared_error: 0.0365 - lr: 1.1220e-04\n",
      "Epoch 3/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.1699 - mean_squared_error: 0.3701\n",
      "Epoch 3: loss improved from 0.22386 to 0.16990, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.1699 - mean_squared_error: 0.3702 - val_loss: 0.0087 - val_mean_squared_error: 0.0175 - lr: 1.2589e-04\n",
      "Epoch 4/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.1435 - mean_squared_error: 0.3065\n",
      "Epoch 4: loss improved from 0.16990 to 0.14351, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.1435 - mean_squared_error: 0.3065 - val_loss: 0.0048 - val_mean_squared_error: 0.0095 - lr: 1.4125e-04\n",
      "Epoch 5/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.1209 - mean_squared_error: 0.2563\n",
      "Epoch 5: loss improved from 0.14351 to 0.12093, saving model to weights.hdf5\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 0.1209 - mean_squared_error: 0.2563 - val_loss: 0.0015 - val_mean_squared_error: 0.0029 - lr: 1.5849e-04\n",
      "Epoch 6/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.1010 - mean_squared_error: 0.2114\n",
      "Epoch 6: loss improved from 0.12093 to 0.10090, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.1009 - mean_squared_error: 0.2112 - val_loss: 0.0017 - val_mean_squared_error: 0.0034 - lr: 1.7783e-04\n",
      "Epoch 7/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.0849 - mean_squared_error: 0.1766\n",
      "Epoch 7: loss improved from 0.10090 to 0.08479, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0848 - mean_squared_error: 0.1764 - val_loss: 0.0016 - val_mean_squared_error: 0.0031 - lr: 1.9953e-04\n",
      "Epoch 8/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.0673 - mean_squared_error: 0.1384\n",
      "Epoch 8: loss improved from 0.08479 to 0.06735, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0673 - mean_squared_error: 0.1384 - val_loss: 0.0030 - val_mean_squared_error: 0.0060 - lr: 2.2387e-04\n",
      "Epoch 9/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.0534 - mean_squared_error: 0.1088\n",
      "Epoch 9: loss improved from 0.06735 to 0.05340, saving model to weights.hdf5\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 0.0534 - mean_squared_error: 0.1088 - val_loss: 0.0026 - val_mean_squared_error: 0.0051 - lr: 2.5119e-04\n",
      "Epoch 10/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.0414 - mean_squared_error: 0.0834\n",
      "Epoch 10: loss improved from 0.05340 to 0.04137, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0414 - mean_squared_error: 0.0834 - val_loss: 0.0020 - val_mean_squared_error: 0.0040 - lr: 2.8184e-04\n",
      "Epoch 11/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.0306 - mean_squared_error: 0.0614\n",
      "Epoch 11: loss improved from 0.04137 to 0.03058, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0306 - mean_squared_error: 0.0614 - val_loss: 0.0018 - val_mean_squared_error: 0.0036 - lr: 3.1623e-04\n",
      "Epoch 12/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.0229 - mean_squared_error: 0.0458\n",
      "Epoch 12: loss improved from 0.03058 to 0.02287, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0229 - mean_squared_error: 0.0458 - val_loss: 0.0015 - val_mean_squared_error: 0.0029 - lr: 3.5481e-04\n",
      "Epoch 13/150\n",
      "180/183 [============================>.] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0317\n",
      "Epoch 13: loss improved from 0.02287 to 0.01583, saving model to weights.hdf5\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 0.0158 - mean_squared_error: 0.0317 - val_loss: 0.0012 - val_mean_squared_error: 0.0025 - lr: 3.9811e-04\n",
      "Epoch 14/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0221\n",
      "Epoch 14: loss improved from 0.01583 to 0.01105, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 0.0110 - mean_squared_error: 0.0221 - val_loss: 0.0014 - val_mean_squared_error: 0.0029 - lr: 4.4668e-04\n",
      "Epoch 15/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.0072 - mean_squared_error: 0.0144\n",
      "Epoch 15: loss improved from 0.01105 to 0.00721, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 0.0072 - mean_squared_error: 0.0144 - val_loss: 0.0010 - val_mean_squared_error: 0.0020 - lr: 5.0119e-04\n",
      "Epoch 16/150\n",
      "180/183 [============================>.] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0103\n",
      "Epoch 16: loss improved from 0.00721 to 0.00516, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 0.0052 - mean_squared_error: 0.0103 - val_loss: 0.0011 - val_mean_squared_error: 0.0023 - lr: 5.6234e-04\n",
      "Epoch 17/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0070\n",
      "Epoch 17: loss improved from 0.00516 to 0.00350, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0070 - val_loss: 0.0013 - val_mean_squared_error: 0.0026 - lr: 6.3096e-04\n",
      "Epoch 18/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0048\n",
      "Epoch 18: loss improved from 0.00350 to 0.00242, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 0.0024 - mean_squared_error: 0.0048 - val_loss: 8.3058e-04 - val_mean_squared_error: 0.0017 - lr: 7.0795e-04\n",
      "Epoch 19/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0036\n",
      "Epoch 19: loss improved from 0.00242 to 0.00182, saving model to weights.hdf5\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 0.0018 - mean_squared_error: 0.0036 - val_loss: 8.2082e-04 - val_mean_squared_error: 0.0016 - lr: 7.9433e-04\n",
      "Epoch 20/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.0015 - mean_squared_error: 0.0030\n",
      "Epoch 20: loss improved from 0.00182 to 0.00151, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0015 - mean_squared_error: 0.0030 - val_loss: 8.5783e-04 - val_mean_squared_error: 0.0017 - lr: 8.9125e-04\n",
      "Epoch 21/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.0013 - mean_squared_error: 0.0026\n",
      "Epoch 21: loss improved from 0.00151 to 0.00129, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0013 - mean_squared_error: 0.0026 - val_loss: 7.7547e-04 - val_mean_squared_error: 0.0016 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.0012 - mean_squared_error: 0.0024\n",
      "Epoch 22: loss improved from 0.00129 to 0.00120, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0012 - mean_squared_error: 0.0024 - val_loss: 7.2409e-04 - val_mean_squared_error: 0.0014 - lr: 0.0011\n",
      "Epoch 23/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.0011 - mean_squared_error: 0.0022\n",
      "Epoch 23: loss improved from 0.00120 to 0.00112, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0011 - mean_squared_error: 0.0022 - val_loss: 7.3870e-04 - val_mean_squared_error: 0.0015 - lr: 0.0013\n",
      "Epoch 24/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.0011 - mean_squared_error: 0.0022\n",
      "Epoch 24: loss improved from 0.00112 to 0.00109, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0011 - mean_squared_error: 0.0022 - val_loss: 7.8229e-04 - val_mean_squared_error: 0.0016 - lr: 0.0014\n",
      "Epoch 25/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.0011 - mean_squared_error: 0.0022\n",
      "Epoch 25: loss did not improve from 0.00109\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0011 - mean_squared_error: 0.0022 - val_loss: 6.6679e-04 - val_mean_squared_error: 0.0013 - lr: 0.0016\n",
      "Epoch 26/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.0010 - mean_squared_error: 0.0020\n",
      "Epoch 26: loss improved from 0.00109 to 0.00101, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0010 - mean_squared_error: 0.0020 - val_loss: 6.1705e-04 - val_mean_squared_error: 0.0012 - lr: 0.0018\n",
      "Epoch 27/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.0010 - mean_squared_error: 0.0020\n",
      "Epoch 27: loss did not improve from 0.00101\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 0.0010 - mean_squared_error: 0.0020 - val_loss: 5.7734e-04 - val_mean_squared_error: 0.0012 - lr: 0.0020\n",
      "Epoch 28/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 9.5189e-04 - mean_squared_error: 0.0019\n",
      "Epoch 28: loss improved from 0.00101 to 0.00095, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 9.5283e-04 - mean_squared_error: 0.0019 - val_loss: 6.3676e-04 - val_mean_squared_error: 0.0013 - lr: 0.0022\n",
      "Epoch 29/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.8143e-04 - mean_squared_error: 0.0020\n",
      "Epoch 29: loss did not improve from 0.00095\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 9.8042e-04 - mean_squared_error: 0.0020 - val_loss: 8.9619e-04 - val_mean_squared_error: 0.0018 - lr: 0.0025\n",
      "Epoch 30/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.4528e-04 - mean_squared_error: 0.0019\n",
      "Epoch 30: loss improved from 0.00095 to 0.00094, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 9.4479e-04 - mean_squared_error: 0.0019 - val_loss: 6.0213e-04 - val_mean_squared_error: 0.0012 - lr: 0.0028\n",
      "Epoch 31/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 9.2973e-04 - mean_squared_error: 0.0019\n",
      "Epoch 31: loss improved from 0.00094 to 0.00093, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 9.2934e-04 - mean_squared_error: 0.0019 - val_loss: 5.0960e-04 - val_mean_squared_error: 0.0010 - lr: 0.0032\n",
      "Epoch 32/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 9.6824e-04 - mean_squared_error: 0.0019\n",
      "Epoch 32: loss did not improve from 0.00093\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 9.6824e-04 - mean_squared_error: 0.0019 - val_loss: 5.4596e-04 - val_mean_squared_error: 0.0011 - lr: 0.0035\n",
      "Epoch 33/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 9.4851e-04 - mean_squared_error: 0.0019\n",
      "Epoch 33: loss did not improve from 0.00093\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 9.4851e-04 - mean_squared_error: 0.0019 - val_loss: 9.9070e-04 - val_mean_squared_error: 0.0020 - lr: 0.0040\n",
      "Epoch 34/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 9.5322e-04 - mean_squared_error: 0.0019\n",
      "Epoch 34: loss did not improve from 0.00093\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 9.5322e-04 - mean_squared_error: 0.0019 - val_loss: 7.6370e-04 - val_mean_squared_error: 0.0015 - lr: 0.0045\n",
      "Epoch 35/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.5003e-04 - mean_squared_error: 0.0019\n",
      "Epoch 35: loss did not improve from 0.00093\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 9.4906e-04 - mean_squared_error: 0.0019 - val_loss: 0.0013 - val_mean_squared_error: 0.0027 - lr: 0.0050\n",
      "Epoch 36/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 9.9967e-04 - mean_squared_error: 0.0020\n",
      "Epoch 36: loss did not improve from 0.00093\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 9.9967e-04 - mean_squared_error: 0.0020 - val_loss: 5.1479e-04 - val_mean_squared_error: 0.0010 - lr: 0.0056\n",
      "Epoch 37/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.0011 - mean_squared_error: 0.0021\n",
      "Epoch 37: loss did not improve from 0.00093\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0011 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0042 - lr: 0.0063\n",
      "Epoch 38/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.3296e-04 - mean_squared_error: 0.0019\n",
      "Epoch 38: loss did not improve from 0.00093\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 9.3931e-04 - mean_squared_error: 0.0019 - val_loss: 0.0012 - val_mean_squared_error: 0.0024 - lr: 0.0071\n",
      "Epoch 39/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.0011 - mean_squared_error: 0.0022\n",
      "Epoch 39: loss did not improve from 0.00093\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 0.0011 - mean_squared_error: 0.0022 - val_loss: 9.1826e-04 - val_mean_squared_error: 0.0018 - lr: 0.0079\n",
      "Epoch 40/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.0010 - mean_squared_error: 0.0021\n",
      "Epoch 40: loss did not improve from 0.00093\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 0.0010 - mean_squared_error: 0.0021 - val_loss: 0.0014 - val_mean_squared_error: 0.0028 - lr: 0.0089\n",
      "Epoch 41/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.2392e-04 - mean_squared_error: 0.0018\n",
      "Epoch 41: loss improved from 0.00093 to 0.00092, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 9.2497e-04 - mean_squared_error: 0.0018 - val_loss: 5.0996e-04 - val_mean_squared_error: 0.0010 - lr: 0.0100\n",
      "Epoch 42/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 9.9984e-04 - mean_squared_error: 0.0020\n",
      "Epoch 42: loss did not improve from 0.00092\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 0.0010 - mean_squared_error: 0.0020 - val_loss: 6.1682e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 43/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 9.2070e-04 - mean_squared_error: 0.0018\n",
      "Epoch 43: loss improved from 0.00092 to 0.00092, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 9.2070e-04 - mean_squared_error: 0.0018 - val_loss: 4.9150e-04 - val_mean_squared_error: 9.8300e-04 - lr: 0.0100\n",
      "Epoch 44/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.6305e-04 - mean_squared_error: 0.0017\n",
      "Epoch 44: loss improved from 0.00092 to 0.00086, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 8.6062e-04 - mean_squared_error: 0.0017 - val_loss: 8.7811e-04 - val_mean_squared_error: 0.0018 - lr: 0.0100\n",
      "Epoch 45/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.4207e-04 - mean_squared_error: 0.0019\n",
      "Epoch 45: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 9.4093e-04 - mean_squared_error: 0.0019 - val_loss: 0.0013 - val_mean_squared_error: 0.0026 - lr: 0.0100\n",
      "Epoch 46/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 9.0169e-04 - mean_squared_error: 0.0018\n",
      "Epoch 46: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 9.0222e-04 - mean_squared_error: 0.0018 - val_loss: 7.8108e-04 - val_mean_squared_error: 0.0016 - lr: 0.0100\n",
      "Epoch 47/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.8398e-04 - mean_squared_error: 0.0018\n",
      "Epoch 47: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 8.8407e-04 - mean_squared_error: 0.0018 - val_loss: 5.9027e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 48/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.7118e-04 - mean_squared_error: 0.0017\n",
      "Epoch 48: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 8.7002e-04 - mean_squared_error: 0.0017 - val_loss: 8.4173e-04 - val_mean_squared_error: 0.0017 - lr: 0.0100\n",
      "Epoch 49/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.6291e-04 - mean_squared_error: 0.0017\n",
      "Epoch 49: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 8.6168e-04 - mean_squared_error: 0.0017 - val_loss: 8.6034e-04 - val_mean_squared_error: 0.0017 - lr: 0.0100\n",
      "Epoch 50/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.0018e-04 - mean_squared_error: 0.0018\n",
      "Epoch 50: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.9983e-04 - mean_squared_error: 0.0018 - val_loss: 7.2910e-04 - val_mean_squared_error: 0.0015 - lr: 0.0100\n",
      "Epoch 51/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.7786e-04 - mean_squared_error: 0.0018\n",
      "Epoch 51: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.7769e-04 - mean_squared_error: 0.0018 - val_loss: 8.6821e-04 - val_mean_squared_error: 0.0017 - lr: 0.0100\n",
      "Epoch 52/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.6896e-04 - mean_squared_error: 0.0017\n",
      "Epoch 52: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 8.6896e-04 - mean_squared_error: 0.0017 - val_loss: 5.6132e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 53/150\n",
      "180/183 [============================>.] - ETA: 0s - loss: 9.2730e-04 - mean_squared_error: 0.0019\n",
      "Epoch 53: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 9.3208e-04 - mean_squared_error: 0.0019 - val_loss: 5.0245e-04 - val_mean_squared_error: 0.0010 - lr: 0.0100\n",
      "Epoch 54/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.7997e-04 - mean_squared_error: 0.0018\n",
      "Epoch 54: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 8.7915e-04 - mean_squared_error: 0.0018 - val_loss: 6.1448e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 55/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.2594e-04 - mean_squared_error: 0.0019\n",
      "Epoch 55: loss did not improve from 0.00086\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 9.2572e-04 - mean_squared_error: 0.0019 - val_loss: 4.8439e-04 - val_mean_squared_error: 9.6877e-04 - lr: 0.0100\n",
      "Epoch 56/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.4264e-04 - mean_squared_error: 0.0017\n",
      "Epoch 56: loss improved from 0.00086 to 0.00084, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 8.4264e-04 - mean_squared_error: 0.0017 - val_loss: 6.6564e-04 - val_mean_squared_error: 0.0013 - lr: 0.0100\n",
      "Epoch 57/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.7576e-04 - mean_squared_error: 0.0018\n",
      "Epoch 57: loss did not improve from 0.00084\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 8.8059e-04 - mean_squared_error: 0.0018 - val_loss: 4.8399e-04 - val_mean_squared_error: 9.6798e-04 - lr: 0.0100\n",
      "Epoch 58/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.8584e-04 - mean_squared_error: 0.0018\n",
      "Epoch 58: loss did not improve from 0.00084\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 8.8867e-04 - mean_squared_error: 0.0018 - val_loss: 9.8582e-04 - val_mean_squared_error: 0.0020 - lr: 0.0100\n",
      "Epoch 59/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.5475e-04 - mean_squared_error: 0.0017\n",
      "Epoch 59: loss did not improve from 0.00084\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.5359e-04 - mean_squared_error: 0.0017 - val_loss: 6.1303e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 60/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.8485e-04 - mean_squared_error: 0.0018\n",
      "Epoch 60: loss did not improve from 0.00084\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.8280e-04 - mean_squared_error: 0.0018 - val_loss: 9.5548e-04 - val_mean_squared_error: 0.0019 - lr: 0.0100\n",
      "Epoch 61/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.9215e-04 - mean_squared_error: 0.0018\n",
      "Epoch 61: loss did not improve from 0.00084\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.9215e-04 - mean_squared_error: 0.0018 - val_loss: 7.0070e-04 - val_mean_squared_error: 0.0014 - lr: 0.0100\n",
      "Epoch 62/150\n",
      "180/183 [============================>.] - ETA: 0s - loss: 8.9600e-04 - mean_squared_error: 0.0018\n",
      "Epoch 62: loss did not improve from 0.00084\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 9.0395e-04 - mean_squared_error: 0.0018 - val_loss: 9.2211e-04 - val_mean_squared_error: 0.0018 - lr: 0.0100\n",
      "Epoch 63/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.4053e-04 - mean_squared_error: 0.0019\n",
      "Epoch 63: loss did not improve from 0.00084\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 9.4007e-04 - mean_squared_error: 0.0019 - val_loss: 6.1045e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 64/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.4797e-04 - mean_squared_error: 0.0017\n",
      "Epoch 64: loss did not improve from 0.00084\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.4797e-04 - mean_squared_error: 0.0017 - val_loss: 6.7066e-04 - val_mean_squared_error: 0.0013 - lr: 0.0100\n",
      "Epoch 65/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 9.0518e-04 - mean_squared_error: 0.0018\n",
      "Epoch 65: loss did not improve from 0.00084\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 9.0518e-04 - mean_squared_error: 0.0018 - val_loss: 5.6182e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 66/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.1803e-04 - mean_squared_error: 0.0016\n",
      "Epoch 66: loss improved from 0.00084 to 0.00082, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 8.1803e-04 - mean_squared_error: 0.0016 - val_loss: 7.1561e-04 - val_mean_squared_error: 0.0014 - lr: 0.0100\n",
      "Epoch 67/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.3166e-04 - mean_squared_error: 0.0017\n",
      "Epoch 67: loss did not improve from 0.00082\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 8.3398e-04 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 0.0024 - lr: 0.0100\n",
      "Epoch 68/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 9.5224e-04 - mean_squared_error: 0.0019\n",
      "Epoch 68: loss did not improve from 0.00082\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 9.5277e-04 - mean_squared_error: 0.0019 - val_loss: 5.2671e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 69/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.9879e-04 - mean_squared_error: 0.0018\n",
      "Epoch 69: loss did not improve from 0.00082\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.9879e-04 - mean_squared_error: 0.0018 - val_loss: 5.8357e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 70/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 9.9291e-04 - mean_squared_error: 0.0020\n",
      "Epoch 70: loss did not improve from 0.00082\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 9.9291e-04 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 0.0024 - lr: 0.0100\n",
      "Epoch 71/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.4568e-04 - mean_squared_error: 0.0017\n",
      "Epoch 71: loss did not improve from 0.00082\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 8.4963e-04 - mean_squared_error: 0.0017 - val_loss: 5.1029e-04 - val_mean_squared_error: 0.0010 - lr: 0.0100\n",
      "Epoch 72/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.1955e-04 - mean_squared_error: 0.0016\n",
      "Epoch 72: loss did not improve from 0.00082\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 8.1977e-04 - mean_squared_error: 0.0016 - val_loss: 9.2750e-04 - val_mean_squared_error: 0.0019 - lr: 0.0100\n",
      "Epoch 73/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.7114e-04 - mean_squared_error: 0.0015\n",
      "Epoch 73: loss improved from 0.00082 to 0.00077, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 7.7126e-04 - mean_squared_error: 0.0015 - val_loss: 6.6361e-04 - val_mean_squared_error: 0.0013 - lr: 0.0100\n",
      "Epoch 74/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.5277e-04 - mean_squared_error: 0.0017\n",
      "Epoch 74: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.6080e-04 - mean_squared_error: 0.0017 - val_loss: 0.0010 - val_mean_squared_error: 0.0020 - lr: 0.0100\n",
      "Epoch 75/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.3410e-04 - mean_squared_error: 0.0017\n",
      "Epoch 75: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.3410e-04 - mean_squared_error: 0.0017 - val_loss: 5.8190e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 76/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.7282e-04 - mean_squared_error: 0.0017\n",
      "Epoch 76: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 8.7165e-04 - mean_squared_error: 0.0017 - val_loss: 4.2109e-04 - val_mean_squared_error: 8.4218e-04 - lr: 0.0100\n",
      "Epoch 77/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.5078e-04 - mean_squared_error: 0.0017\n",
      "Epoch 77: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.5078e-04 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0030 - lr: 0.0100\n",
      "Epoch 78/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.5204e-04 - mean_squared_error: 0.0017\n",
      "Epoch 78: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.5204e-04 - mean_squared_error: 0.0017 - val_loss: 8.1628e-04 - val_mean_squared_error: 0.0016 - lr: 0.0100\n",
      "Epoch 79/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.2605e-04 - mean_squared_error: 0.0017\n",
      "Epoch 79: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.2534e-04 - mean_squared_error: 0.0017 - val_loss: 7.0612e-04 - val_mean_squared_error: 0.0014 - lr: 0.0100\n",
      "Epoch 80/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.2784e-04 - mean_squared_error: 0.0017\n",
      "Epoch 80: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 8.2784e-04 - mean_squared_error: 0.0017 - val_loss: 5.9022e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 81/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.3578e-04 - mean_squared_error: 0.0017\n",
      "Epoch 81: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.3562e-04 - mean_squared_error: 0.0017 - val_loss: 7.8207e-04 - val_mean_squared_error: 0.0016 - lr: 0.0100\n",
      "Epoch 82/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.8860e-04 - mean_squared_error: 0.0016\n",
      "Epoch 82: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.8860e-04 - mean_squared_error: 0.0016 - val_loss: 0.0016 - val_mean_squared_error: 0.0031 - lr: 0.0100\n",
      "Epoch 83/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.5638e-04 - mean_squared_error: 0.0017\n",
      "Epoch 83: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.5667e-04 - mean_squared_error: 0.0017 - val_loss: 4.6965e-04 - val_mean_squared_error: 9.3931e-04 - lr: 0.0100\n",
      "Epoch 84/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 9.0111e-04 - mean_squared_error: 0.0018\n",
      "Epoch 84: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 8.9871e-04 - mean_squared_error: 0.0018 - val_loss: 4.3266e-04 - val_mean_squared_error: 8.6533e-04 - lr: 0.0100\n",
      "Epoch 85/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.1675e-04 - mean_squared_error: 0.0016\n",
      "Epoch 85: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.1581e-04 - mean_squared_error: 0.0016 - val_loss: 4.7041e-04 - val_mean_squared_error: 9.4082e-04 - lr: 0.0100\n",
      "Epoch 86/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.3843e-04 - mean_squared_error: 0.0017\n",
      "Epoch 86: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.3697e-04 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 0.0022 - lr: 0.0100\n",
      "Epoch 87/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.9215e-04 - mean_squared_error: 0.0018\n",
      "Epoch 87: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.9275e-04 - mean_squared_error: 0.0018 - val_loss: 4.9013e-04 - val_mean_squared_error: 9.8026e-04 - lr: 0.0100\n",
      "Epoch 88/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.1276e-04 - mean_squared_error: 0.0016\n",
      "Epoch 88: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 8.1158e-04 - mean_squared_error: 0.0016 - val_loss: 5.6918e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 89/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.6068e-04 - mean_squared_error: 0.0017\n",
      "Epoch 89: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.6153e-04 - mean_squared_error: 0.0017 - val_loss: 9.5495e-04 - val_mean_squared_error: 0.0019 - lr: 0.0100\n",
      "Epoch 90/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.7797e-04 - mean_squared_error: 0.0016\n",
      "Epoch 90: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 7.7797e-04 - mean_squared_error: 0.0016 - val_loss: 6.5595e-04 - val_mean_squared_error: 0.0013 - lr: 0.0100\n",
      "Epoch 91/150\n",
      "180/183 [============================>.] - ETA: 0s - loss: 8.6220e-04 - mean_squared_error: 0.0017\n",
      "Epoch 91: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.6858e-04 - mean_squared_error: 0.0017 - val_loss: 8.7449e-04 - val_mean_squared_error: 0.0017 - lr: 0.0100\n",
      "Epoch 92/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.7817e-04 - mean_squared_error: 0.0016\n",
      "Epoch 92: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 7.7874e-04 - mean_squared_error: 0.0016 - val_loss: 0.0015 - val_mean_squared_error: 0.0029 - lr: 0.0100\n",
      "Epoch 93/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.4451e-04 - mean_squared_error: 0.0017\n",
      "Epoch 93: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.4446e-04 - mean_squared_error: 0.0017 - val_loss: 6.0931e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 94/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.9259e-04 - mean_squared_error: 0.0016\n",
      "Epoch 94: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 7.9259e-04 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 0.0022 - lr: 0.0100\n",
      "Epoch 95/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.1073e-04 - mean_squared_error: 0.0016\n",
      "Epoch 95: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.1081e-04 - mean_squared_error: 0.0016 - val_loss: 7.1380e-04 - val_mean_squared_error: 0.0014 - lr: 0.0100\n",
      "Epoch 96/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.7001e-04 - mean_squared_error: 0.0015\n",
      "Epoch 96: loss improved from 0.00077 to 0.00077, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 7.7044e-04 - mean_squared_error: 0.0015 - val_loss: 4.4573e-04 - val_mean_squared_error: 8.9145e-04 - lr: 0.0100\n",
      "Epoch 97/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.7072e-04 - mean_squared_error: 0.0017\n",
      "Epoch 97: loss did not improve from 0.00077\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.6936e-04 - mean_squared_error: 0.0017 - val_loss: 4.5882e-04 - val_mean_squared_error: 9.1764e-04 - lr: 0.0100\n",
      "Epoch 98/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.5866e-04 - mean_squared_error: 0.0015\n",
      "Epoch 98: loss improved from 0.00077 to 0.00076, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 7.5885e-04 - mean_squared_error: 0.0015 - val_loss: 4.2270e-04 - val_mean_squared_error: 8.4540e-04 - lr: 0.0100\n",
      "Epoch 99/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.2890e-04 - mean_squared_error: 0.0017\n",
      "Epoch 99: loss did not improve from 0.00076\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.2911e-04 - mean_squared_error: 0.0017 - val_loss: 4.3200e-04 - val_mean_squared_error: 8.6399e-04 - lr: 0.0100\n",
      "Epoch 100/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.4005e-04 - mean_squared_error: 0.0015\n",
      "Epoch 100: loss improved from 0.00076 to 0.00074, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 7.4208e-04 - mean_squared_error: 0.0015 - val_loss: 4.6216e-04 - val_mean_squared_error: 9.2431e-04 - lr: 0.0100\n",
      "Epoch 101/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.3762e-04 - mean_squared_error: 0.0017\n",
      "Epoch 101: loss did not improve from 0.00074\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.3657e-04 - mean_squared_error: 0.0017 - val_loss: 5.3503e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 102/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.9022e-04 - mean_squared_error: 0.0016\n",
      "Epoch 102: loss did not improve from 0.00074\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 7.9022e-04 - mean_squared_error: 0.0016 - val_loss: 5.9648e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 103/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.0941e-04 - mean_squared_error: 0.0016\n",
      "Epoch 103: loss did not improve from 0.00074\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.0636e-04 - mean_squared_error: 0.0016 - val_loss: 5.4167e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 104/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.6285e-04 - mean_squared_error: 0.0015\n",
      "Epoch 104: loss did not improve from 0.00074\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.6215e-04 - mean_squared_error: 0.0015 - val_loss: 0.0010 - val_mean_squared_error: 0.0020 - lr: 0.0100\n",
      "Epoch 105/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.8427e-04 - mean_squared_error: 0.0016\n",
      "Epoch 105: loss did not improve from 0.00074\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.8360e-04 - mean_squared_error: 0.0016 - val_loss: 5.3170e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 106/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.5519e-04 - mean_squared_error: 0.0017\n",
      "Epoch 106: loss did not improve from 0.00074\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.5675e-04 - mean_squared_error: 0.0017 - val_loss: 8.5481e-04 - val_mean_squared_error: 0.0017 - lr: 0.0100\n",
      "Epoch 107/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.0820e-04 - mean_squared_error: 0.0016\n",
      "Epoch 107: loss did not improve from 0.00074\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.0791e-04 - mean_squared_error: 0.0016 - val_loss: 4.5387e-04 - val_mean_squared_error: 9.0775e-04 - lr: 0.0100\n",
      "Epoch 108/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.2493e-04 - mean_squared_error: 0.0014\n",
      "Epoch 108: loss improved from 0.00074 to 0.00072, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 7.2449e-04 - mean_squared_error: 0.0014 - val_loss: 4.2543e-04 - val_mean_squared_error: 8.5086e-04 - lr: 0.0100\n",
      "Epoch 109/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 8.5793e-04 - mean_squared_error: 0.0017\n",
      "Epoch 109: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 8.5695e-04 - mean_squared_error: 0.0017 - val_loss: 4.3326e-04 - val_mean_squared_error: 8.6653e-04 - lr: 0.0100\n",
      "Epoch 110/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.3790e-04 - mean_squared_error: 0.0015\n",
      "Epoch 110: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.3790e-04 - mean_squared_error: 0.0015 - val_loss: 5.7314e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 111/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.5386e-04 - mean_squared_error: 0.0017\n",
      "Epoch 111: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.5386e-04 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_mean_squared_error: 0.0046 - lr: 0.0100\n",
      "Epoch 112/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.9198e-04 - mean_squared_error: 0.0016\n",
      "Epoch 112: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.9462e-04 - mean_squared_error: 0.0016 - val_loss: 7.7514e-04 - val_mean_squared_error: 0.0016 - lr: 0.0100\n",
      "Epoch 113/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.2270e-04 - mean_squared_error: 0.0016\n",
      "Epoch 113: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 8.2270e-04 - mean_squared_error: 0.0016 - val_loss: 5.7602e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 114/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.8653e-04 - mean_squared_error: 0.0016\n",
      "Epoch 114: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 7.8705e-04 - mean_squared_error: 0.0016 - val_loss: 4.8625e-04 - val_mean_squared_error: 9.7249e-04 - lr: 0.0100\n",
      "Epoch 115/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 8.1552e-04 - mean_squared_error: 0.0016\n",
      "Epoch 115: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 8.1552e-04 - mean_squared_error: 0.0016 - val_loss: 6.2539e-04 - val_mean_squared_error: 0.0013 - lr: 0.0100\n",
      "Epoch 116/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.5032e-04 - mean_squared_error: 0.0015\n",
      "Epoch 116: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.5032e-04 - mean_squared_error: 0.0015 - val_loss: 5.3194e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 117/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.9789e-04 - mean_squared_error: 0.0016\n",
      "Epoch 117: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 7.9789e-04 - mean_squared_error: 0.0016 - val_loss: 4.2611e-04 - val_mean_squared_error: 8.5223e-04 - lr: 0.0100\n",
      "Epoch 118/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.6974e-04 - mean_squared_error: 0.0015\n",
      "Epoch 118: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.6915e-04 - mean_squared_error: 0.0015 - val_loss: 8.7859e-04 - val_mean_squared_error: 0.0018 - lr: 0.0100\n",
      "Epoch 119/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.6060e-04 - mean_squared_error: 0.0015\n",
      "Epoch 119: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 7.6368e-04 - mean_squared_error: 0.0015 - val_loss: 7.0440e-04 - val_mean_squared_error: 0.0014 - lr: 0.0100\n",
      "Epoch 120/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.7446e-04 - mean_squared_error: 0.0015\n",
      "Epoch 120: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.7796e-04 - mean_squared_error: 0.0016 - val_loss: 4.0513e-04 - val_mean_squared_error: 8.1026e-04 - lr: 0.0100\n",
      "Epoch 121/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.7792e-04 - mean_squared_error: 0.0016\n",
      "Epoch 121: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 7.8001e-04 - mean_squared_error: 0.0016 - val_loss: 6.5443e-04 - val_mean_squared_error: 0.0013 - lr: 0.0100\n",
      "Epoch 122/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.1712e-04 - mean_squared_error: 0.0016\n",
      "Epoch 122: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.1793e-04 - mean_squared_error: 0.0016 - val_loss: 0.0021 - val_mean_squared_error: 0.0042 - lr: 0.0100\n",
      "Epoch 123/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.2304e-04 - mean_squared_error: 0.0016\n",
      "Epoch 123: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.2244e-04 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 0.0021 - lr: 0.0100\n",
      "Epoch 124/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.2340e-04 - mean_squared_error: 0.0016\n",
      "Epoch 124: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.2365e-04 - mean_squared_error: 0.0016 - val_loss: 4.1118e-04 - val_mean_squared_error: 8.2237e-04 - lr: 0.0100\n",
      "Epoch 125/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.7566e-04 - mean_squared_error: 0.0016\n",
      "Epoch 125: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.7566e-04 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0029 - lr: 0.0100\n",
      "Epoch 126/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.3977e-04 - mean_squared_error: 0.0015\n",
      "Epoch 126: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 7.4095e-04 - mean_squared_error: 0.0015 - val_loss: 4.5686e-04 - val_mean_squared_error: 9.1373e-04 - lr: 0.0100\n",
      "Epoch 127/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.2526e-04 - mean_squared_error: 0.0015\n",
      "Epoch 127: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.2455e-04 - mean_squared_error: 0.0014 - val_loss: 4.1890e-04 - val_mean_squared_error: 8.3780e-04 - lr: 0.0100\n",
      "Epoch 128/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.2255e-04 - mean_squared_error: 0.0016\n",
      "Epoch 128: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.2223e-04 - mean_squared_error: 0.0016 - val_loss: 6.9786e-04 - val_mean_squared_error: 0.0014 - lr: 0.0100\n",
      "Epoch 129/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.3064e-04 - mean_squared_error: 0.0015\n",
      "Epoch 129: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.3300e-04 - mean_squared_error: 0.0015 - val_loss: 7.5464e-04 - val_mean_squared_error: 0.0015 - lr: 0.0100\n",
      "Epoch 130/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.5353e-04 - mean_squared_error: 0.0015\n",
      "Epoch 130: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 7.5243e-04 - mean_squared_error: 0.0015 - val_loss: 5.2941e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 131/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.5393e-04 - mean_squared_error: 0.0015\n",
      "Epoch 131: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.5525e-04 - mean_squared_error: 0.0015 - val_loss: 0.0010 - val_mean_squared_error: 0.0020 - lr: 0.0100\n",
      "Epoch 132/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.2256e-04 - mean_squared_error: 0.0014\n",
      "Epoch 132: loss improved from 0.00072 to 0.00072, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.2256e-04 - mean_squared_error: 0.0014 - val_loss: 5.8965e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 133/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.4257e-04 - mean_squared_error: 0.0015\n",
      "Epoch 133: loss did not improve from 0.00072\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 7.4196e-04 - mean_squared_error: 0.0015 - val_loss: 0.0023 - val_mean_squared_error: 0.0045 - lr: 0.0100\n",
      "Epoch 134/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.1992e-04 - mean_squared_error: 0.0014\n",
      "Epoch 134: loss improved from 0.00072 to 0.00072, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.2141e-04 - mean_squared_error: 0.0014 - val_loss: 4.5764e-04 - val_mean_squared_error: 9.1527e-04 - lr: 0.0100\n",
      "Epoch 135/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 6.8197e-04 - mean_squared_error: 0.0014\n",
      "Epoch 135: loss improved from 0.00072 to 0.00069, saving model to weights.hdf5\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 6.8941e-04 - mean_squared_error: 0.0014 - val_loss: 0.0019 - val_mean_squared_error: 0.0037 - lr: 0.0100\n",
      "Epoch 136/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.0209e-04 - mean_squared_error: 0.0016\n",
      "Epoch 136: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.0076e-04 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0028 - lr: 0.0100\n",
      "Epoch 137/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.4005e-04 - mean_squared_error: 0.0015\n",
      "Epoch 137: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 5s 26ms/step - loss: 7.4043e-04 - mean_squared_error: 0.0015 - val_loss: 5.0045e-04 - val_mean_squared_error: 0.0010 - lr: 0.0100\n",
      "Epoch 138/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.6850e-04 - mean_squared_error: 0.0015\n",
      "Epoch 138: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.6850e-04 - mean_squared_error: 0.0015 - val_loss: 4.3920e-04 - val_mean_squared_error: 8.7841e-04 - lr: 0.0100\n",
      "Epoch 139/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.3781e-04 - mean_squared_error: 0.0015\n",
      "Epoch 139: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 7.3867e-04 - mean_squared_error: 0.0015 - val_loss: 7.4991e-04 - val_mean_squared_error: 0.0015 - lr: 0.0100\n",
      "Epoch 140/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.4791e-04 - mean_squared_error: 0.0015\n",
      "Epoch 140: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.4841e-04 - mean_squared_error: 0.0015 - val_loss: 3.9319e-04 - val_mean_squared_error: 7.8639e-04 - lr: 0.0100\n",
      "Epoch 141/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.3012e-04 - mean_squared_error: 0.0015\n",
      "Epoch 141: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 7.2774e-04 - mean_squared_error: 0.0015 - val_loss: 4.5045e-04 - val_mean_squared_error: 9.0090e-04 - lr: 0.0100\n",
      "Epoch 142/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.5186e-04 - mean_squared_error: 0.0015\n",
      "Epoch 142: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.5612e-04 - mean_squared_error: 0.0015 - val_loss: 5.3719e-04 - val_mean_squared_error: 0.0011 - lr: 0.0100\n",
      "Epoch 143/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 8.1160e-04 - mean_squared_error: 0.0016\n",
      "Epoch 143: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 8.1023e-04 - mean_squared_error: 0.0016 - val_loss: 5.8651e-04 - val_mean_squared_error: 0.0012 - lr: 0.0100\n",
      "Epoch 144/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.3359e-04 - mean_squared_error: 0.0015\n",
      "Epoch 144: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.3446e-04 - mean_squared_error: 0.0015 - val_loss: 4.0753e-04 - val_mean_squared_error: 8.1506e-04 - lr: 0.0100\n",
      "Epoch 145/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 7.8665e-04 - mean_squared_error: 0.0016\n",
      "Epoch 145: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 7.8623e-04 - mean_squared_error: 0.0016 - val_loss: 4.1226e-04 - val_mean_squared_error: 8.2452e-04 - lr: 0.0100\n",
      "Epoch 146/150\n",
      "181/183 [============================>.] - ETA: 0s - loss: 7.9187e-04 - mean_squared_error: 0.0016\n",
      "Epoch 146: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 7.9052e-04 - mean_squared_error: 0.0016 - val_loss: 7.2667e-04 - val_mean_squared_error: 0.0015 - lr: 0.0100\n",
      "Epoch 147/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.3881e-04 - mean_squared_error: 0.0015\n",
      "Epoch 147: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.3881e-04 - mean_squared_error: 0.0015 - val_loss: 3.3893e-04 - val_mean_squared_error: 6.7786e-04 - lr: 0.0100\n",
      "Epoch 148/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.2872e-04 - mean_squared_error: 0.0015\n",
      "Epoch 148: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 22ms/step - loss: 7.2872e-04 - mean_squared_error: 0.0015 - val_loss: 3.5328e-04 - val_mean_squared_error: 7.0656e-04 - lr: 0.0100\n",
      "Epoch 149/150\n",
      "182/183 [============================>.] - ETA: 0s - loss: 6.9604e-04 - mean_squared_error: 0.0014\n",
      "Epoch 149: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 6.9634e-04 - mean_squared_error: 0.0014 - val_loss: 4.9160e-04 - val_mean_squared_error: 9.8319e-04 - lr: 0.0100\n",
      "Epoch 150/150\n",
      "183/183 [==============================] - ETA: 0s - loss: 7.2737e-04 - mean_squared_error: 0.0015\n",
      "Epoch 150: loss did not improve from 0.00069\n",
      "183/183 [==============================] - 4s 21ms/step - loss: 7.2737e-04 - mean_squared_error: 0.0015 - val_loss: 4.0704e-04 - val_mean_squared_error: 8.1409e-04 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "seq_length = 23\n",
    "batch_size = 100\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "\n",
    "NAME = \"{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "# Create and Fit the LSTM Network\n",
    "model = Sequential()\n",
    "# model.add(LSTM(32, input_shape=(look_back+1, 1), activation='sigmoid', return_sequences=True))\n",
    "# model.add(LSTM(32, activation='sigmoid'))\n",
    "print(x_data.shape)\n",
    "model.add(LSTM(32, input_shape=(x_data.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32, input_shape=(x_data.shape[1:])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-4 * 10**(epoch / 20) if (1e-4 * 10**(epoch / 20)<1e-2) else 1e-2)\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"weights.hdf5\", monitor=\"loss\", verbose=1, save_best_only=True, save_weights_only=True)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"huber_loss\",\n",
    "              optimizer=adam,\n",
    "              metrics=[\"mean_squared_error\"])\n",
    "print(model.summary())\n",
    "\n",
    "print(\"Starting to fit\")\n",
    "history = model.fit(x_data, y_data, \n",
    "                    epochs=150, \n",
    "                    batch_size=batch_size, \n",
    "                    validation_split = 0.2, \n",
    "                    verbose=1, \n",
    "                    callbacks=[lr_schedule, checkpointer, tensorboard])\n",
    "model.load_weights('weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cdfdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Evaluation\n",
      "(22823, 24)\n",
      "(22823,)\n"
     ]
    }
   ],
   "source": [
    "print('Test Data Evaluation')\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "# print(model.evaluate(x = x_data, y = y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e650a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
